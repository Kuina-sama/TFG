{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DependencyDataset\\ConvAI2\\convai_rel_complete.json','r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones y clases auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(dataset,encoding):\n",
    "    if encoding == 'relative':\n",
    "        vocab0 = set()\n",
    "        vocab1 = set()\n",
    "\n",
    "        for item in list(dataset.values()):\n",
    "            for dep_label in item[encoding]:\n",
    "                dep_label_split = dep_label.split('_')\n",
    "                vocab0.add(dep_label_split[0])\n",
    "                vocab1.add(dep_label_split[1])\n",
    "\n",
    "    return (vocab0,vocab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dependency_labels(dataset,vocabs,encoding):\n",
    "    token_data = {}\n",
    "    if encoding == 'relative':\n",
    "        for index, item in enumerate(dataset):\n",
    "            vocab0 , vocab1 = vocabs\n",
    "            aux = [x.split('_') for x in dataset[item][encoding]]\n",
    "            token_data[index] = {#'text':item,\n",
    "                        'tag0':[aux[i][0] for i in range(len(aux))],\n",
    "                        'tag1':[aux[i][1] for i in range(len(aux))]}\n",
    "\n",
    "    return token_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch dataset\n",
    "\n",
    "class MyDependencyDataSet(Dataset):\n",
    "    def __init__(self,data,word_to_indx):\n",
    "        self.data = data\n",
    "        self.word_to_indx0 , self.word_to_indx1 = word_to_indx\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        \n",
    "        x = self.data[index]\n",
    "\n",
    "        tag0 = torch.tensor([self.word_to_indx0[tag] for tag in x['tag0']])\n",
    "\n",
    "        tag1 = torch.tensor([self.word_to_indx1[tag] for tag in x['tag1']])\n",
    "\n",
    "        sample = {'tag0': tag0,\n",
    "                'tag1': tag1}\n",
    "\n",
    "        return  sample\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación vocabularios y conversión a índices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el relative encoding creo dos vocabularios: Uno con la parte que codifica la posición de la cabeza y otro con la parte que codifica el tag de dependencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab0, vocab1 = create_vocabulary(data,'relative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de cada vocabulario: \n",
      "\n",
      "Vocabulario posición: 79 elementos\n",
      "Vocabulario dependency tag: 49 elementos\n"
     ]
    }
   ],
   "source": [
    "print('Tamaño de cada vocabulario: \\n')\n",
    "print(f'Vocabulario posición: {len(vocab0)} elementos')\n",
    "print(f'Vocabulario dependency tag: {len(vocab1)} elementos')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debo crear los diccionarios que me permitan mapear cada palabra a un índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_indx0 = {word: i for i,word in enumerate(vocab0)}\n",
    "word_to_indx1 = {word: i for i,word in enumerate(vocab1)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un diccionario con todos los dependency tags convertidos a índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = tokenize_dependency_labels(data,(vocab0,vocab1),'relative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tag0': ['1', '-2', '-1', '3', '2', '1', '-5', '-1', '-2', '1', '-2', '1', '-2', '-1', '-13'], 'tag1': ['amod', 'root', 'punct', 'nsubj', 'aux', 'advmod', 'parataxis', 'compound:prt', 'obj', 'nsubj', 'acl:relcl', 'mark', 'xcomp', 'advmod', 'punct']}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación dataset y dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo hago ya con dataset y dataloader porque para el modelo global tendré que usarlo (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_tokenized_data = MyDependencyDataSet(tokenized_data,(word_to_indx0,word_to_indx1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag0': tensor([28, 44, 29, 71, 19, 28, 12, 29, 44, 28, 44, 28, 44, 29, 66]),\n",
       " 'tag1': tensor([11,  4, 23, 14, 24,  0, 15, 43, 38, 14, 46,  8,  3,  0, 23])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_tokenized_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(pytorch_tokenized_data,batch_size=16,shuffle=True,collate_fn=data_collator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_enc(torch.nn.Module):\n",
    "    def __init__(self,embedding_dim,hidden_dim,vocab_sizes):\n",
    "        super(LSTM_enc,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_emb0 = nn.Embedding(vocab_sizes[0],embedding_dim)\n",
    "        self.word_emb1 = nn.Embedding(vocab_sizes[1],embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim * 2,hidden_dim)\n",
    "\n",
    "    def forward(self,tag0,tag1):\n",
    "        emb0 = self.word_emb0(tag0)\n",
    "        emb1 = self.word_emb1(tag1)\n",
    "\n",
    "        embeds = torch.cat((emb0,emb1),1)\n",
    "        \n",
    "        lstm_out = self.lstm(embeds)\n",
    "\n",
    "        return lstm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "embedding_dim = 100\n",
    "vocab_sizes = (len(vocab0),len(vocab1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM_enc(embedding_dim,hidden_dim,vocab_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag0': tensor([28, 44, 29, 71, 19, 28, 12, 29, 44, 28, 44, 28, 44, 29, 66]),\n",
       " 'tag1': tensor([11,  4, 23, 14, 24,  0, 15, 43, 38, 14, 46,  8,  3,  0, 23])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output , (hidden_state, cell_state) = lstm_model(**pytorch_tokenized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35e8332e99bdf485583869dfbdef293dcf2f9293b1663ec5daea0a573af457c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
