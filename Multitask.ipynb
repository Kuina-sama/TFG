{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,load_metric\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding,AutoModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import AdamW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y preprocesado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer que utilizaremos y función auxiliar para aplicarlo.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(item):\n",
    "    '''Aplica el tokenizer al elemento dado. Trunca su longitud a la \n",
    "    longitud máxima de DistilBert.\n",
    "    '''\n",
    "    return tokenizer(item[\"text\"],truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset md_gender_bias (C:\\Users\\kuina\\.cache\\huggingface\\datasets\\md_gender_bias\\wizard\\1.0.0\\8ae77b51acf93383161cc954b146159291beca6c979b54ce228c46db86116c05)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637f51c0abe44f57bc64fb9838b6fbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset('md_gender_bias','wizard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo test y validación. Creo datos artificiales para las etiquetas que faltan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = data[\"train\"]\n",
    "about = train[\"gender\"]\n",
    "self = [np.random.choice(np.unique(about)) for i in range(len(about))]\n",
    "partner = [np.random.choice(np.unique(about)) for i in range(len(about))]\n",
    "\n",
    "\n",
    "eval = data[\"validation\"]\n",
    "aboutE = eval[\"gender\"]\n",
    "selfE = [np.random.choice(np.unique(aboutE)) for i in range(len(aboutE))]\n",
    "partnerE = [np.random.choice(np.unique(aboutE)) for i in range(len(aboutE))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = [ ( about[i] , self[i] , partner[i] ) for i in range(len(about))]\n",
    "labels_eval = [ ( aboutE[i] , selfE[i] , partnerE[i] ) for i in range(len(aboutE))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1749da54538047df83921f94b4e37b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25839e2ec82463e9749302d90a18153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a573943a5b3d44c288b5aca655987458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_data = data.map(preprocess_function,batched=True)\n",
    "token_data = token_data.remove_columns([\"chosen_topic\",\"text\",\"gender\"])\n",
    "token_data= token_data.with_format(\"torch\")\n",
    "\n",
    "\n",
    "token_train = token_data[\"train\"]\n",
    "token_eval = token_data[\"validation\"]\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un dataset a partir de los datos iniciales.\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self,data,labels,attention_mask):\n",
    "        self.data = data\n",
    "        self.labels =labels \n",
    "        self.attention = attention_mask\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "            \n",
    "        x = self.data[index]\n",
    "        labels =  self.labels[index]\n",
    "        labels = np.array([labels])\n",
    "        # labels = labels.astype('float')\n",
    "        labels = labels\n",
    "        attention = self.attention[index]\n",
    "\n",
    "\n",
    "        sample = {'input_ids': x,\n",
    "                'attention_mask': attention,\n",
    "                'labels': torch.from_numpy(labels).view(-1,3)}\n",
    "\n",
    "        return  sample\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo los dataloaders con ambos conjuntos. Aplico padding de forma dinámica haciendo uso del DataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = MyDataSet(token_train['input_ids'],labels_train,token_train['attention_mask'])\n",
    "evalData = MyDataSet(token_eval['input_ids'],labels_eval,token_eval['attention_mask'])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(trainData,batch_size=16,shuffle=True,collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(evalData,batch_size=16,shuffle=True,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi(nn.Module):\n",
    "    def __init__(self,name,num_labels,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.encoder = AutoModel.from_pretrained(name,num_labels=num_labels,output_attentions=True,output_hidden_states = True)\n",
    "        self.task = nn.ModuleList([])\n",
    "        self.task.append(nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(768,num_labels)\n",
    "            # nn.Softmax()\n",
    "        ))\n",
    "        self.traceAbout = []\n",
    "        self.traceSelf = []\n",
    "        self.tracePartner = []\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self,input_ids = None,attention_mask = None,labels = None,output_attentions=None,output_hidden_states=None):\n",
    "        \n",
    "\n",
    "\n",
    "        dBertoutputs = self.encoder(input_ids,attention_mask = attention_mask,output_attentions=output_attentions,output_hidden_states = output_hidden_states)\n",
    "\n",
    "\n",
    "        outputs_last_hidden_state = dBertoutputs[0]\n",
    "\n",
    "        cls_out = outputs_last_hidden_state[:,0]\n",
    "\n",
    "        about = cls_out.detach().clone()\n",
    "        Self = cls_out.detach().clone() \n",
    "        partner = cls_out.detach().clone()  \n",
    "\n",
    "        for layer in self.task:\n",
    "            about = layer(about)\n",
    "            self.traceAbout.append(about)\n",
    "            Self = layer(Self)\n",
    "            self.traceSelf.append(Self)\n",
    "            partner = layer(partner)\n",
    "            self.tracePartner.append(partner)\n",
    "\n",
    "\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            aboutLoss = loss_fct(about , labels[:,0][:,0])\n",
    "            SelfLoss = loss_fct(Self , labels[:,0][:,1])\n",
    "            partnerLoss = loss_fct(partner , labels[:,0][:,2])\n",
    "\n",
    "            loss = aboutLoss + SelfLoss + partnerLoss\n",
    "\n",
    "\n",
    "        return SequenceClassifierOutput(loss=loss, logits=(about,Self,partner), hidden_states=dBertoutputs.hidden_states,attentions=dBertoutputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = Multi(\"distilbert-base-uncased\", 3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7669943d1544a1aab03b80a7b17d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 654/1962 [00:13<00:20, 64.48it/s]\n",
      " 67%|██████▋   | 1308/1962 [00:22<00:09, 70.91it/s]\n",
      "100%|██████████| 1962/1962 [00:32<00:00, 67.77it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "train_function(model,num_epochs,train_dataloader,optimizer = AdamW(model.parameters(),lr=5e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(model,metric,eval_dataloader,task = 0):\n",
    "    '''Función para evaluar un modelo dado en la tarea indicada.\n",
    "    \n",
    "    model: modelo a evaluar\n",
    "    metric: metrica a utilizar en la evaluación.\n",
    "    eval_dataloader: conjunto para evaluar. Debe ser un Pytorch DataLoader. \n",
    "    task: tarea en la que queremos evaluar el modelo'''\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        \n",
    "        # logits = outputs.logits \n",
    "        logits = outputs.logits[task] \n",
    "        predictions = torch.argmax(logits,dim=-1)\n",
    "        metric.add_batch(predictions = predictions, references = batch[\"labels\"][:,0][:,task])\n",
    "\n",
    "    return metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos en la tarea 0 (about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7057728119180633}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_function(model,metric,eval_dataloader,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1 (self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3687150837988827}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_function(model,metric,eval_dataloader,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 2 (partner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.32774674115456237}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_function(model,metric,eval_dataloader,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    break \n",
    "batch = {k:v.to(device) for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.encoder(batch['input_ids'],attention_mask = batch['attention_mask'],output_attentions=True,output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "about, self, partner = outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones en la etiqueta about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(about,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][:,0][:,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35e8332e99bdf485583869dfbdef293dcf2f9293b1663ec5daea0a573af457c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
