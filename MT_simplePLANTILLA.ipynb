{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD ,AdamW\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_generic as generic\n",
    "import multitask_simple as mt\n",
    "import model_confs as confs\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "torch.manual_seed(27)\n",
    "tasks = ['to','as','about']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = confs.distilbert_conf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos ConvAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Datasets\\ConvAI2\\convai2_complete.json','r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convai_train = data['train']\n",
    "convai_val = data['validation']\n",
    "\n",
    "\n",
    "\n",
    "convai_train_token = generic.tokenize_dataset(convai_train,tasks,model_conf) \n",
    "convai_val_token = generic.tokenize_dataset(convai_val,tasks,model_conf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convai_train_dataset = mt.DatasetMultiTaskSimple(convai_train_token,tasks,eval=False)\n",
    "convai_val_dataset = mt.DatasetMultiTaskSimple(convai_val_token,tasks,eval=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos md_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Datasets\\md_gender\\md_complete.json','r',encoding=\"utf8\") as f:\n",
    "    md_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_tokenized = generic.tokenize_dataset(md_data,tasks,model_conf) \n",
    "md_dataset = mt.DatasetMultiTaskSimple(md_tokenized,tasks,eval=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train =DataLoader(convai_train_dataset,batch_size=128,shuffle=True,collate_fn=mt.collate_fn)\n",
    "dl_val =DataLoader(convai_val_dataset,batch_size=128,shuffle=True,collate_fn=mt.collate_fn)\n",
    "dl_eval = DataLoader(md_dataset,batch_size=128,shuffle=False,collate_fn=mt.collate_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mt.MultiTaskSimple(model_conf).to(device)\n",
    "save_path='SAVE_PATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy evaluando en todas las etiquetas\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks))\n",
    "print(\"Accuracy evaluando en etiquetas female\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks,'female'))\n",
    "print(\"Accuracy evaluando en etiquetas male\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks,'male'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "num_epochs = 100\n",
    "train.train_function_multi(model,num_epochs,dl_train,optimizer,early_stop = 10,dl_val = dl_val,save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mt.MultiTaskSimple(model_conf).to(device)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "print(\"Accuracy evaluando en todas las etiquetas\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks))\n",
    "print(\"Accuracy evaluando en etiquetas female\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks,'female'))\n",
    "print(\"Accuracy evaluando en etiquetas male\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks,'male'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mt.MultiTaskSimple(model_conf).to(device)\n",
    "save_path='SAVE_PATH'\n",
    "learning_rate = 5e-5\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 100\n",
    "train.train_function_multi(model,num_epochs,dl_train,optimizer,early_stop = 10,dl_val = dl_val,save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mt.MultiTaskSimple(model_conf).to(device)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "print(\"Accuracy evaluando en todas las etiquetas\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks))\n",
    "print(\"Accuracy evaluando en etiquetas female\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks,'female'))\n",
    "print(\"Accuracy evaluando en etiquetas male\")\n",
    "print(train.eval_function_multi(model,dl_eval,tasks,'male'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35e8332e99bdf485583869dfbdef293dcf2f9293b1663ec5daea0a573af457c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
