{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding,AutoModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import nn\n",
    "from torch.optim import AdamW \n",
    "\n",
    "\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "from my_utils import train_function\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar este bloque a archivo auxiliar\n",
    "\n",
    "text_to_num = {'to':{'PARTNER:female':0,'PARTNER:male':1,\"PARTNER:unknown\":2},\n",
    "                'as':{'SELF:female':0, 'SELF:male':1,'SELF:unknown':2},\n",
    "                'about':{'ABOUT:female':0,'ABOUT:male':1,'ABOUT:unknown':2}}\n",
    "\n",
    "num_to_text = {'to':{0:'PARTNER:female',1:'PARTNER:male',2:\"PARTNER:unknown\"},\n",
    "                'as':{0:'SELF:female', 1:'SELF:male',2:'SELF:unknown'},\n",
    "                'about':{0:'ABOUT:female',1:'ABOUT:male',2:'ABOUT:unknown'}}\n",
    "\n",
    "tasks_names = ['about','as','to']\n",
    "\n",
    "\n",
    "task_to_num =  {'about':0,'as':1,'to':2}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases y funciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta sección está pendiente de pasar a un archivo separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary():\n",
    "    def __init__(self,data,encoding):\n",
    "        self.encoding = encoding\n",
    "        self._create_vocabulary(data,encoding)\n",
    "\n",
    "        self.word_to_indx = []\n",
    "        for i in self.vocabs:\n",
    "            self.word_to_indx.append({word: i for i,word in enumerate(self.vocabs[i])})\n",
    "\n",
    "\n",
    "\n",
    "    def get_vocab_sizes(self):\n",
    "        vocabs_len = []\n",
    "        for i in self.vocabs:\n",
    "            vocabs_len.append(len(self.vocabs[i]))\n",
    "\n",
    "        return vocabs_len\n",
    "\n",
    "    def total_vocabs(self):\n",
    "        return len(self.word_to_indx)\n",
    "\n",
    "    def _create_vocabulary(self,dataset,encoding):\n",
    "        \"\"\"Para otro tipo de encoding dará fallo, pendiente apliarlo\"\"\"\n",
    "        if encoding == 'relative':\n",
    "            num_splits = 2\n",
    "            split_separator = '_'\n",
    "\n",
    "        self.vocabs = {}\n",
    "        for i in range(num_splits):\n",
    "            self.vocabs[i] = set()\n",
    "\n",
    "\n",
    "        for item in list(dataset.values()):\n",
    "            for dep_label in item[encoding]:\n",
    "                dep_label_split = dep_label.split(split_separator)\n",
    "\n",
    "                \n",
    "                for indx in range(num_splits):\n",
    "\n",
    "                    self.vocabs[indx].add(dep_label_split[indx])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset_with_dependencies(dataset,tokenizer,tasks_names,vocab):\n",
    "    \"\"\"Por el momento funciona para encoding relative\"\"\"\n",
    "    token_data = {}\n",
    "    for index, text in enumerate(dataset):\n",
    "        tokenized = tokenizer(text,truncation=True)\n",
    "\n",
    "        labels ={}\n",
    "        for task in tasks_names:\n",
    "            aux_label = [text_to_num[task][x] for x in dataset[text][f'label_{task}']]\n",
    "\n",
    "\n",
    "            labels[task] = aux_label\n",
    "\n",
    "        # Esta parte procesa los tags de dependencia\n",
    "        aux = [x.split('_') for x in dataset[text][vocab.encoding]]\n",
    "\n",
    "        dep_tags = {}\n",
    "        for x in range(vocab.total_vocabs()):\n",
    "            dep_tags[f'tag{x}'] = [vocab.word_to_indx[x][aux[i][x]] for i in range(len(aux))]\n",
    "\n",
    "\n",
    "        #Junto todo en un nuevo dataset\n",
    "        token_data[index] = {'text':text,\n",
    "                                'input_ids':tokenized.input_ids,\n",
    "                                'attention_mask':tokenized.attention_mask,\n",
    "                                'labels':labels,\n",
    "                                'dep_tags':dep_tags}\n",
    "\n",
    "    return token_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y procesado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DependencyDataset\\ConvAI2\\convai_rel_complete.json','r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(data,'relative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data = tokenize_dataset_with_dependencies(data,tokenizer,tasks_names,vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self,token_data,tasks):\n",
    "        self.data = token_data\n",
    "        self.tasks = tasks\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "            \n",
    "        x = torch.tensor(self.data[index]['input_ids'])\n",
    "        \n",
    "        attention = torch.tensor(self.data[index]['attention_mask'])\n",
    "        # Etiquetas de las dimensiones correspondientes\n",
    "        raw_labels = self.data[index]['labels'] \n",
    "\n",
    "        labels=[]\n",
    "        for task in self.tasks:\n",
    "            aux = raw_labels[task]\n",
    "            if len(aux)>1:\n",
    "                label = np.random.choice(aux)\n",
    "                if label ==2:\n",
    "                    label = np.random.choice([0,1])\n",
    "                labels.append(label)\n",
    "            elif len(aux)==1:\n",
    "                if aux[0] == 2:\n",
    "\n",
    "                    label = np.random.choice([0,1])\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    labels.append(aux[0])\n",
    "\n",
    "        \n",
    "        dep_tags = []\n",
    "        for item in self.data[index]['dep_tags']:\n",
    "            dep_tags.append(self.data[index]['dep_tags'][item])\n",
    "\n",
    "\n",
    "        sample = {'input_ids': x,\n",
    "                'attention_mask': attention,\n",
    "                'labels': labels,\n",
    "                'dep_tags':torch.tensor(dep_tags),\n",
    "                'num_vocabs':len(dep_tags)\n",
    "                }\n",
    "        return  sample\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tengo que crear mi propia función porque si no me da problemas con los tensores del parsing.\n",
    "def collate_fn(batch):\n",
    "\n",
    "    input_ids = [d['input_ids'] for d in batch]\n",
    "    input_ids = pad_sequence(input_ids,batch_first=True)\n",
    "\n",
    "    labels = [d['labels'] for d in batch]\n",
    "    labels=torch.tensor(labels)\n",
    "\n",
    "\n",
    "    attention = [b['attention_mask'] for b in batch]\n",
    "    attention_mask = pad_sequence(attention,batch_first=True)\n",
    "\n",
    "    num_vocabs = batch[0]['num_vocabs']\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    dep_tags = [d['dep_tags'] for d in batch]\n",
    "    aux_dep = {}\n",
    "    for j in range(num_vocabs):\n",
    "        aux_dep[j] = [dep_tags[i][j] for i in range(batch_size)]\n",
    "        aux_dep[j] = pad_sequence(aux_dep[j],batch_first=True)\n",
    "\n",
    "    deps = [aux_dep[i].tolist() for i in range(num_vocabs)]\n",
    "    \n",
    "\n",
    "    return {'input_ids':input_ids, 'attention_mask':attention_mask, 'labels':labels.view(-1,len(labels)),'dep_tags': torch.tensor(deps)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MyDataSet(token_data=token_data,tasks=tasks_names)\n",
    "dl_train = DataLoader(dataset_train,batch_size=3,shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "embedding_dim = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_enc(torch.nn.Module):\n",
    "    def __init__(self,embedding_dim,hidden_dim,vocab):\n",
    "        super(LSTM_enc,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_sizes = vocab.get_vocab_sizes()\n",
    "\n",
    "        self.num_vocabs = len(self.vocab_sizes)\n",
    "\n",
    "        self.emb_layers = nn.ModuleList([])\n",
    "        for i in range(self.num_vocabs):\n",
    "            self.emb_layers.append(nn.Embedding(self.vocab_sizes[i],embedding_dim)) \n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim * self.num_vocabs,hidden_dim,batch_first = True)\n",
    "\n",
    "    def forward(self,dep_tags):\n",
    "\n",
    "\n",
    "        embeds = []\n",
    "\n",
    "        for i in range(len(dep_tags)):\n",
    "\n",
    "            e = self.emb_layers[i](dep_tags[i])\n",
    "\n",
    "            embeds.append(e)\n",
    "\n",
    "\n",
    "        concat_embeds = torch.cat(embeds,2)\n",
    "\n",
    "\n",
    "        return self.lstm(concat_embeds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo multi con parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiWithDependencies(nn.Module):\n",
    "    def __init__(self,name,num_labels,tasks_names,vocab,embedding_dim=100,lstm_hidden_dim=128,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "\n",
    "        # Procesado texto\n",
    "        self.encoder = AutoModel.from_pretrained(name,num_labels=num_labels,output_attentions=True,output_hidden_states = True)\n",
    "        self.taskLayer = nn.ModuleList([])\n",
    "        self.taskLayer.append(nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(768+lstm_hidden_dim,num_labels)\n",
    "        ))\n",
    "\n",
    "\n",
    "        \n",
    "        self.task_to_num =  {'about':0,'as':1,'to':2}\n",
    "\n",
    "        \n",
    "        if len(tasks_names) ==1:\n",
    "            self.task = self.task_to_num[tasks_names[0]]\n",
    "            self.SingleTask = True\n",
    "        else:\n",
    "            self.SingleTask=False\n",
    "            self.tasksname = {v:k for v,k in enumerate(tasks_names)}\n",
    "        \n",
    "        # Procesado de los dependency tags\n",
    "        \n",
    "        self.LSTM_model = LSTM_enc(embedding_dim,lstm_hidden_dim,vocab)\n",
    "\n",
    "    def forward(self,input_ids = None,attention_mask = None,labels = None,dep_tags = None,output_attentions=None,output_hidden_states=None):\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        dBertoutputs = self.encoder(input_ids,attention_mask = attention_mask,output_attentions=output_attentions,output_hidden_states = output_hidden_states)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        outputs_last_hidden_state = dBertoutputs[0]\n",
    "\n",
    "        cls_out = outputs_last_hidden_state[:,0]\n",
    "\n",
    "\n",
    "        lstm_out , (lstm_hidden_state, cell_state) = self.LSTM_model(dep_tags)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        concat_output = torch.cat((cls_out,lstm_hidden_state.squeeze()),1)\n",
    "\n",
    "        if self.SingleTask:\n",
    "            tasks_output = concat_output.clone()\n",
    "            for layer in self.taskLayer:\n",
    "                tasks_output = layer(tasks_output)\n",
    "\n",
    "        else:\n",
    "            tasks_output = {v : concat_output.clone() for v in self.tasksname.keys()}\n",
    "\n",
    "            for layer in self.taskLayer:\n",
    "                tasks_output = {v: layer(k) for v,k in tasks_output.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "            if self.SingleTask:\n",
    "\n",
    "                loss = loss_fct(tasks_output[0] , labels[0][:,self.task].type('torch.FloatTensor').to(device)) \n",
    "            else:\n",
    "\n",
    "                task_loss = [loss_fct(tasks_output[i] , labels[:,i]) for i in range(len(tasks_output))]\n",
    "                loss = sum(task_loss)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        return SequenceClassifierOutput(loss=loss, logits=tasks_output, hidden_states=dBertoutputs.hidden_states,attentions=dBertoutputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = MultiWithDependencies(\"distilbert-base-uncased\", 2,tasks_names,vocab,embedding_dim,lstm_hidden_dim=hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ea19ec8a4c48d7a7f9e3fd534a2045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24466/24466 [15:17<00:00, 27.14it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "train_function(model,num_epochs,dl_train,optimizer = AdamW(model.parameters(),lr=5e-5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35e8332e99bdf485583869dfbdef293dcf2f9293b1663ec5daea0a573af457c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
