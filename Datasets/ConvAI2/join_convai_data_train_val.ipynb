{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\kuina\\OneDrive\\TFG\\Codigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "from utils_creacion_datasets import create_dependency_tags\n",
    "\n",
    "from utils_generic import text_to_num,num_to_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos Huggingface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset md_gender_bias (C:\\Users\\kuina\\.cache\\huggingface\\datasets\\md_gender_bias\\convai2_inferred\\1.0.0\\8ae77b51acf93383161cc954b146159291beca6c979b54ce228c46db86116c05)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa0177cf8d44d74a4eac2a58e6112a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\", 'binary_label': 1, 'binary_score': 0.6521999835968018, 'ternary_label': 2, 'ternary_score': 0.4496000111103058}\n"
     ]
    }
   ],
   "source": [
    "convai2_about = load_dataset('md_gender_bias','convai2_inferred')\n",
    "train_about = convai2_about['train']\n",
    "print(train_about[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'binary_label'],\n",
      "    num_rows: 131438\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_about = train_about.remove_columns(['binary_score', 'ternary_label', 'ternary_score'])\n",
    "print(train_about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos antes de filtrar repetidos = 131438\n",
      "Elementos después de filtrar repetidos = 115877\n"
     ]
    }
   ],
   "source": [
    "#Filtro repetidos para que sean una única entrada (Aqui aun no estoy filtrando las etiquetas)\n",
    "dataT = {}\n",
    "print(f'Elementos antes de filtrar repetidos = {len(train_about)}')\n",
    "for item in train_about:\n",
    "    text = item['text']\n",
    "    label = item['binary_label']\n",
    "    if text not in dataT:\n",
    "        # data[text] =[label]\n",
    "        dataT[text] =[num_to_text['about'][label]]\n",
    "    else:\n",
    "        dataT[text].append(num_to_text['about'][label])\n",
    "\n",
    "print(f'Elementos después de filtrar repetidos = {len(dataT)}')\n",
    "\n",
    "# Filtro las etiquetas para que no haya items repetidos\n",
    "\n",
    "for item in dataT:\n",
    "    dataT[item] = list(set(dataT[item]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'hello what are doing today ?', 'binary_label': 1, 'binary_score': 0.5015000104904175, 'ternary_label': 1, 'ternary_score': 0.3422999978065491}\n",
      "Dataset({\n",
      "    features: ['text', 'binary_label'],\n",
      "    num_rows: 7801\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_about = convai2_about['validation']\n",
    "print(val_about[0])\n",
    "val_about = val_about.remove_columns(['binary_score', 'ternary_label', 'ternary_score'])\n",
    "print(val_about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos antes de filtrar repetidos = 7801\n",
      "Elementos después de filtrar repetidos = 7503\n"
     ]
    }
   ],
   "source": [
    "#Filtro repetidos para que sean una única entrada (Aqui aun no estoy filtrando las etiquetas)\n",
    "dataV = {}\n",
    "print(f'Elementos antes de filtrar repetidos = {len(val_about)}')\n",
    "for item in val_about:\n",
    "    text = item['text']\n",
    "    label = item['binary_label']\n",
    "    if text not in dataV:\n",
    "        # data[text] =[label]\n",
    "        dataV[text] =[num_to_text['about'][label]]\n",
    "    else:\n",
    "        dataV[text].append(num_to_text['about'][label])\n",
    "\n",
    "print(f'Elementos después de filtrar repetidos = {len(dataV)}')\n",
    "\n",
    "# Filtro las etiquetas para que no haya items repetidos\n",
    "\n",
    "for item in dataV:\n",
    "    dataV[item] = list(set(dataV[item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga datos ParlAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./convai2_parlai_train.json') as f: #Este tiene unks\n",
    "    convai2_parlai_train = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./convai2_parlai_val.json') as f: #Este tiene unks\n",
    "    convai2_parlai_val = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unión de los datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me interesa tener 3 etiquetas, por lo que quiero las que oraciones que salgan en convai2_parlai y en data (etiquetas about the convai2). Itero sobre convai2_parlai porque es el conjunto más pequeño de los 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data = {}\n",
    "for item in convai2_parlai_train:\n",
    "    if item in dataT:\n",
    "        join_data[item] = {'label_about':dataT[item],\n",
    "                            'label_to':convai2_parlai_train[item]['partner'],\n",
    "                            'label_as':convai2_parlai_train[item]['self']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73398"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(join_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('convai2_complete_train.json','w') as f:\n",
    "    json.dump(join_data,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data = {}\n",
    "for item in convai2_parlai_val:\n",
    "    if item in dataV:\n",
    "        join_data[item] = {'label_about':dataV[item],\n",
    "                            'label_to':convai2_parlai_val[item]['partner'],\n",
    "                            'label_as':convai2_parlai_val[item]['self']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7503"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(join_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('convai2_complete_val.json','w') as f:\n",
    "    json.dump(join_data,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35e8332e99bdf485583869dfbdef293dcf2f9293b1663ec5daea0a573af457c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
